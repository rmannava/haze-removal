\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=0.75in]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{siunitx}
\usepackage{indentfirst}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{caption}

\graphicspath{ {.} }

\pagestyle{fancy}
\fancyhf{}
\rhead{Rama Mannava}
\lhead{Single Image Haze Removal}
\cfoot{\thepage}

\begin{document}
\thispagestyle{plain}
\begin{center}
    {\huge \textbf{Single Image Haze Removal}} \\
    \bigskip
    {\large Rama Mannava (rmannava)}
\end{center}

\bigskip

\section*{Problem}
Haze removal is the process of removing the effects of fog, smoke, and other atmospheric phenomena from an image. Many methods require the use of multiple images to provide the necessary information, but there exist strategies such as the one outlined in \href{http://kaiminghe.com/publications/cvpr09.pdf}{this paper} that make use of a stronger assumption to supplement the under-constrained problem. A dark channel prior can be used to estimate the effect that haze has on light transmission, in addition to the atmospheric light in the scene. This information can then be used to reconstruct the original dehazed scene.

\section*{Solution Approach}
The algorithm consists of several stages that must be performed sequentially. Each stage, however, is performed on individual pixels using context from a patch of surrounding pixels. The pixels of the final image are all constructed independently, so the image can be partitioned into blocks and computation can proceed for the entire image in parallel.

The use of CUDA will greatly improve the performance of this algorithm. The GPU on the GHC machines can support \texttt{46} blocks with \texttt{1024} threads each, which translates to \texttt{47,000} pixels that can be handled at once. If the entire algorithm consisted of calculations on pixels, this would lead to a \texttt{47,000x} speedup over a single threaded CPU-based implementation. However, the algorithm has sections restricted to sequential computation, and time spent computing pixel values will likely be negligible next to the bottleneck caused by transferring data around. Therefore, the actual speedup of a CUDA implementation will be much lower than \texttt{47,000x}. Although a precise estimate would require testing the separate sections of the algorithm, a speedup of \texttt{100x} should be achievable with judicious use of kernel launches and data transfer between host and device. Speedup will be measured on a set of images chosen with differing backgrounds and levels of haze.

\section*{Timeline}
\begin{enumerate}[leftmargin=*, label=\textbf{Week \arabic*:}]
    \item
        Write and test sequential implementation
    \item
        Begin CUDA implementation
    \item
        Finish CUDA implementation and begin testing
    \item
        Finish testing CUDA implementation and begin performance tuning
    \item
        Finish performance tuning and begin comparison testing
    \item
        Finish comparison testing and write final report
\end{enumerate}

\end{document}

